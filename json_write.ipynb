{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Json write ipynb**\n",
    "\n",
    "- reference:  https://bleedai.com/introduction-to-pose-detection-and-basic-pose-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from PIL import Image\n",
    "import mediapipe_helper\n",
    "import ntpath\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **getGifAvgFps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGifAvgFps(pil_ImageObject):\n",
    "    \"\"\" Returns the average framerate of a PIL Image object \"\"\"\n",
    "    pil_ImageObject.seek(0)\n",
    "    frames = duration = 0\n",
    "    while True:\n",
    "        try:\n",
    "            frames += 1\n",
    "            duration += pil_ImageObject.info['duration']\n",
    "            pil_ImageObject.seek(pil_ImageObject.tell() + 1)\n",
    "        except EOFError:\n",
    "            return frames / duration * 1000\n",
    "    return 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mediapipe init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    " \n",
    "# Setting up the Pose function.\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.6, model_complexity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mediapipe detect pose**\n",
    "\n",
    "- This function performs pose detection on an image.\n",
    "    - Args:\n",
    "        - image: The input image with a prominent person whose pose landmarks needs to be detected.\n",
    "        - pose: The pose setup function required to perform the pose detection.\n",
    "        - display: A boolean value that is if set to true the function displays the original input image, the resultant image, \n",
    "       ' and the pose landmarks in 3D plot and returns nothing.\n",
    "    - Returns:\n",
    "        - output_image: The input image with the detected pose landmarks drawn.\n",
    "        - landmarks: A list of detected landmarks converted into their original scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pose World landmarks\n",
    "    - `x`: `-landmark[i].z`\n",
    "    - `y`: `landmark[i].x` \n",
    "    - `z`: `-landmark[i].y`\n",
    "    - `score`:  `landmark[i].visibility`\n",
    "    - `name`: `name_list[i]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "def detectPose(image, pose, jsonObject, frameNum, display=True):\n",
    "    clear_output(wait=True) # for clear console output\n",
    "    # for json_object['frames']\n",
    "    frameJsonObject = {\n",
    "        \"frameNum\": frameNum,\n",
    "        \"keypoints\": [\n",
    "        ],\n",
    "        \"keypoints3D\" : [\n",
    "        ]\n",
    "    }\n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    if results.pose_world_landmarks:\n",
    "        for i in range(0, 33):\n",
    "            landmark = results.pose_world_landmarks.landmark\n",
    "            frameJsonObject[\"keypoints3D\"].append({'x': landmark[i].x,'y': landmark[i].y, 'z': landmark[i].z,'score':  landmark[i].visibility, \"name\": mediapipe_helper.mediapipe_names[i]})\n",
    "            \n",
    "    if results.pose_landmarks:\n",
    "        # Draw Pose landmarks on the output image.\n",
    "        for i in range(0, 33):\n",
    "            landmark = results.pose_landmarks.landmark\n",
    "            frameJsonObject[\"keypoints\"].append({'x': landmark[i].x,'y': landmark[i].y, 'z': landmark[i].z,'score':  landmark[i].visibility, \"name\": mediapipe_helper.mediapipe_names[i]})\n",
    "            \n",
    "    jsonObject[\"frames\"].append(frameJsonObject)\n",
    "        \n",
    "    # Return the output image and the found landmarks.\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_to_mediapipe_json(fileName, maxFrameNum):\n",
    "    FILENAME = os.path.join(os.path.dirname('__file__'),fileName)\n",
    "    # only gif\n",
    "    fps = getGifAvgFps(Image.open(FILENAME))\n",
    "    jsonObject = {\n",
    "        \"fileName\": fileName,\n",
    "        \"duration\": 0,\n",
    "        \"ticksPerSecond\": math.trunc(fps),\n",
    "        \"frames\": [\n",
    "        ]\n",
    "    }\n",
    "    frame_num = -1\n",
    "    pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "    video = cv2.VideoCapture(fileName)\n",
    "    \n",
    "    while video.isOpened():\n",
    "        ok, frame = video.read()\n",
    "        frame_num += 1\n",
    "        if not ok or maxFrameNum < frame_num:\n",
    "            break\n",
    "        frame_height, frame_width, _ =  frame.shape\n",
    "        frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "        frame = detectPose(frame, pose_video, jsonObject, frame_num, display=False)\n",
    "        \n",
    "    jsonObject['duration'] = frame_num -1\n",
    "    video.release()\n",
    "    \n",
    "    return jsonObject\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **All gifs in '/sample' to json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_object = gif_to_mediapipe_json(\"sample/mixamo_attack.gif\", 100)\n",
    "target_pattern = r\"./sample/*.gif\"\n",
    "file_list = glob.glob(target_pattern)\n",
    "file_list = [file.replace('\\\\', '/') for file in file_list]\n",
    "for file in file_list:\n",
    "     json_object = gif_to_mediapipe_json(file , 100)\n",
    "     with open('./output/'+ ntpath.basename(file) +'.json', 'w') as f:\n",
    "         json_string = json.dump(json_object, f, indent=2)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('system-3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78bdb2dcac2d744d0c30d0eaa331d55fe59e60d95f25fb3dacd42cea4b1d7e89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
