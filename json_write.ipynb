{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Json write ipynb**\n",
    "\n",
    "- reference:  https://bleedai.com/introduction-to-pose-detection-and-basic-pose-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from time import time\r\n",
    "import mediapipe as mp\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import json\r\n",
    "from IPython.display import clear_output\r\n",
    "import os\r\n",
    "from PIL import Image\r\n",
    "import mediapipe_helper\r\n",
    "import ntpath\r\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **getGifAvgFps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGifAvgFps(pil_ImageObject):\n",
    "    \"\"\" Returns the average framerate of a PIL Image object \"\"\"\n",
    "    pil_ImageObject.seek(0)\n",
    "    frames = duration = 0\n",
    "    while True:\n",
    "        try:\n",
    "            frames += 1\n",
    "            duration += pil_ImageObject.info['duration']\n",
    "            pil_ImageObject.seek(pil_ImageObject.tell() + 1)\n",
    "        except EOFError:\n",
    "            return frames / duration * 1000\n",
    "    return 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mediapipe init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\r\n",
    " \r\n",
    "# Setting up the Pose function.\r\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.6, model_complexity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mediapipe detect pose**\n",
    "\n",
    "- This function performs pose detection on an image.\n",
    "    - Args:\n",
    "        - image: The input image with a prominent person whose pose landmarks needs to be detected.\n",
    "        - pose: The pose setup function required to perform the pose detection.\n",
    "        - display: A boolean value that is if set to true the function displays the original input image, the resultant image, \n",
    "       ' and the pose landmarks in 3D plot and returns nothing.\n",
    "    - Returns:\n",
    "        - output_image: The input image with the detected pose landmarks drawn.\n",
    "        - landmarks: A list of detected landmarks converted into their original scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pose World landmarks\n",
    "    - `x`: `-landmark[i].z`\n",
    "    - `y`: `landmark[i].x` \n",
    "    - `z`: `-landmark[i].y`\n",
    "    - `score`:  `landmark[i].visibility`\n",
    "    - `name`: `name_list[i]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, jsonObject, frameNum, display=True):\r\n",
    "    clear_output(wait=True) # for clear console output\r\n",
    "    # for json_object['frames']\r\n",
    "    frameJsonObject = {\r\n",
    "        \"frameNum\": frameNum,\r\n",
    "        \"keypoints\": [\r\n",
    "        ],\r\n",
    "        \"keypoints3D\" : [\r\n",
    "        ]\r\n",
    "    }\r\n",
    "    # Create a copy of the input image.\r\n",
    "    output_image = image.copy()\r\n",
    "    \r\n",
    "    # Convert the image from BGR into RGB format.\r\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
    "    \r\n",
    "    # Perform the Pose Detection.\r\n",
    "    results = pose.process(imageRGB)\r\n",
    "\r\n",
    "    if results.pose_world_landmarks:\r\n",
    "        for i in range(0, 33):\r\n",
    "            landmark = results.pose_world_landmarks.landmark\r\n",
    "            frameJsonObject[\"keypoints3D\"].append({'x': landmark[i].x,'y': landmark[i].y, 'z': landmark[i].z,'score':  landmark[i].visibility, \"name\": mediapipe_helper.mediapipe_names[i]})\r\n",
    "            \r\n",
    "    if results.pose_landmarks:\r\n",
    "        # Draw Pose landmarks on the output image.\r\n",
    "        for i in range(0, 33):\r\n",
    "            landmark = results.pose_landmarks.landmark\r\n",
    "            frameJsonObject[\"keypoints\"].append({'x': landmark[i].x,'y': landmark[i].y, 'z': landmark[i].z,'score':  landmark[i].visibility, \"name\": mediapipe_helper.mediapipe_names[i]})\r\n",
    "            \r\n",
    "    jsonObject[\"frames\"].append(frameJsonObject)\r\n",
    "        \r\n",
    "    # Return the output image and the found landmarks.\r\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_to_mediapipe_json(fileName, maxFrameNum):\r\n",
    "    FILENAME = os.path.join(os.path.dirname('__file__'),fileName)\r\n",
    "    # only gif\r\n",
    "    fps = getGifAvgFps(Image.open(FILENAME))\r\n",
    "    jsonObject = {\r\n",
    "        \"fileName\": fileName,\r\n",
    "        \"duration\": 0,\r\n",
    "        \"ticksPerSecond\": math.trunc(fps),\r\n",
    "        \"frames\": [\r\n",
    "        ]\r\n",
    "    }\r\n",
    "    frame_num = -1\r\n",
    "    pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\r\n",
    "    video = cv2.VideoCapture(fileName)\r\n",
    "    \r\n",
    "    while video.isOpened():\r\n",
    "        ok, frame = video.read()\r\n",
    "        frame_num += 1\r\n",
    "        if not ok or maxFrameNum < frame_num:\r\n",
    "            break\r\n",
    "        frame_height, frame_width, _ =  frame.shape\r\n",
    "        frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\r\n",
    "        frame = detectPose(frame, pose_video, jsonObject, frame_num, display=False)\r\n",
    "        \r\n",
    "    jsonObject['duration'] = frame_num -1\r\n",
    "    video.release()\r\n",
    "    \r\n",
    "    return jsonObject\r\n",
    "    \r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **All gifs in '/sample' to json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_object = gif_to_mediapipe_json(\"sample/mixamo_attack.gif\", 100)\r\n",
    "target_pattern = r\"./sample/*.gif\"\r\n",
    "file_list = glob.glob(target_pattern)\r\n",
    "file_list = [file.replace('\\\\', '/') for file in file_list]\r\n",
    "for file in file_list:\r\n",
    "     json_object = gif_to_mediapipe_json(file , 100)\r\n",
    "     with open('./output/'+ ntpath.basename(file) +'.json', 'w') as f:\r\n",
    "         json_string = json.dump(json_object, f, indent=2)    \r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7770f5e8eb6920f79a6b043824678a52812d883996986ad7f79f03ebf5a9088e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('No': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}